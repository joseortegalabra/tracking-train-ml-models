{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5890081a-dfc9-4804-93f6-361c262617a2",
   "metadata": {},
   "source": [
    "# Vertex AI\n",
    "Save the experiments in \"vertex experiments\" and compare the results of differents experiments\n",
    "\n",
    "Introductory level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a1a032-6873-4db3-9cd4-b741f8281c08",
   "metadata": {},
   "source": [
    "### 0. Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852ccb32-65d0-4c1d-83fc-fe321575e363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ml packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "import seaborn as sns\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "\n",
    "# evaluate\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "# vertex gcp\n",
    "from google.cloud import aiplatform as vertex_ai\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251e01cc-44fb-483d-9d03-f0c1fe732829",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "576ed9b2-2add-4fea-b145-0072916137c6",
   "metadata": {},
   "source": [
    "### 1. Load data, EDA, train model\n",
    "In this part we run all the clasic codes to train a machine learning model and save a certain number of variables with important values that we want to save to registry our experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd689604-8fb1-4db6-93e2-d4d497859867",
   "metadata": {},
   "source": [
    "#### 1.1 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1ceb5d-ecd1-4a52-b6c2-5fdf830de7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data_X, data_y = fetch_california_housing(return_X_y=True, as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fed5b9-0494-4dbf-9223-f8ea3200b56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31bd2fb-2b1d-4b0d-ae67-6b9fd4f121f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880a0400-1e28-4780-83d5-5053c0663f34",
   "metadata": {},
   "source": [
    "#### 1.2 EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e075714-35ad-44a7-90fc-f5c93e3745ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA\n",
    "data_X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dba3cb-72b2-4b9c-9241-f74cb7bf7842",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# correlations between features\n",
    "corr = data_X.corr()\n",
    "\n",
    "# Crear un mapa de calor con Matplotlib\n",
    "plt.figure(figsize=(8, 4))\n",
    "heatmap = plt.imshow(corr, cmap='coolwarm', interpolation='none', aspect='auto')\n",
    "\n",
    "# Mostrar los valores en cada celda\n",
    "for i in range(len(corr)):\n",
    "    for j in range(len(corr)):\n",
    "        plt.text(j, i, f'{corr.iloc[i, j]:.2f}', ha='center', va='center', color='w')\n",
    "\n",
    "# Añadir barra de color\n",
    "plt.colorbar(heatmap, fraction=0.046, pad=0.04)\n",
    "\n",
    "# Añadir etiquetas\n",
    "plt.xticks(range(len(corr)), corr.columns, rotation=90)\n",
    "plt.yticks(range(len(corr)), corr.index)\n",
    "\n",
    "# Añadir título\n",
    "plt.title('Correlation Matrix')\n",
    "\n",
    "# save\n",
    "name_correleation_matrix = 'correlation_matrix.png'\n",
    "plt.savefig(name_correleation_matrix)\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8ed4cd-eba9-4b3c-981f-36f3841549a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fedacd-1041-40ed-9449-f0dc023c350c",
   "metadata": {},
   "source": [
    "#### 1.3 split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af80b7a1-1b31-44fc-a9e8-e64271e8639b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_X, data_y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2297ef-2a02-4423-81dc-e201cfadecaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e2d070-55ef-47a2-bf6b-3403ef6a36bd",
   "metadata": {},
   "source": [
    "### 1.4 Values of target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edee841-f1b2-447c-8964-2bd4a1aaf4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistics target\n",
    "y_train_mean = round(y_train.mean(), 2)\n",
    "y_train_std = round(y_train.std(), 2)\n",
    "y_test_mean = round(y_test.mean(), 2)\n",
    "y_test_std = round(y_test.std(), 2)\n",
    "\n",
    "print('statistics target')\n",
    "print(f'--train-- mean = {y_train_mean}, std = {y_train_std}')\n",
    "print(f'--test-- mean = {y_test_mean}, std = {y_test_std}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99c12a5-12ba-4aef-90c0-fac0ba73acda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram target\n",
    "plt.hist(y_train, \n",
    "         color = 'black', \n",
    "         alpha = 0.5,\n",
    "        label = f'--train-- mean = {y_train_mean}, std = {y_train_std}'\n",
    "        )\n",
    "\n",
    "plt.hist(y_test, \n",
    "         color = 'orange', \n",
    "         alpha = 0.5,\n",
    "        label = f'--test-- mean = {y_test_mean}, std = {y_test_std}'\n",
    "        )\n",
    "\n",
    "plt.title('histogram of target train vs test')\n",
    "plt.legend()\n",
    "\n",
    "# save\n",
    "name_histograms_target = 'histograms_target_train_test.png'\n",
    "plt.savefig(name_histograms_target)\n",
    "\n",
    "# show\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ecb45b-bda9-4e0a-81e9-d4f3a2bee43c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640981a3-a901-408b-ad23-dae22aa5e182",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87416516-80d5-4f1b-bc79-a9da5bb4e214",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85890461-d393-47a2-8f23-b6d41ea0b61c",
   "metadata": {},
   "source": [
    "### 2. Train models, evaluate it and save results\n",
    "Train all the models with the same dataset and evaluate with the same dataset\n",
    "\n",
    "Models trained (each model trained is saved in a different run)\n",
    "- linear regression\n",
    "- decision tree\n",
    "- random forest (small)\n",
    "- random forest (medium)\n",
    "- random forest (default)\n",
    "- nn mlp (using sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797e7df4-e1da-4c9b-9729-36abe1c6871b",
   "metadata": {},
   "source": [
    "### 2.0 Auxiliar functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e7fbda-4628-45a2-8ae1-912b6fdb15a8",
   "metadata": {},
   "source": [
    "#### 2.1 Auxiliar functions train/evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d2c588-abeb-4296-9e29-381942687698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_predicted):\n",
    "    \"\"\"\n",
    "    Given \"y_true\" and \"y_predicted\" calculate metrics of performance (r2, rmse, mae)\n",
    "    \"\"\"\n",
    "    r2_metric = r2_score(y_true, y_predicted)\n",
    "\n",
    "    rmse_metric = mean_squared_error(y_true, y_predicted, squared = False)\n",
    "\n",
    "    mae_metric = mean_absolute_error(y_true, y_predicted)\n",
    "\n",
    "    print(\"r2: \", r2_metric)\n",
    "    print(\"rmse: \", rmse_metric)\n",
    "    print(\"mae_metric: \", mae_metric)\n",
    "    return r2_metric, rmse_metric, mae_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcbf12b-acab-4eb1-b91e-d4dee21c16f4",
   "metadata": {},
   "source": [
    "#### 2.2 Auxiliar functions registry runs in vertex Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c362da0e-e2f8-478e-9654-9143905f1bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_instance_tensorboard(experiment_name, experiment_description, project_gcp, location_gcp):\n",
    "    \"\"\"\n",
    "    Create a vertex tensorboard instance. The instance of tensorboard is created with the idea to have the same name of the experiment of vertex ai\n",
    "    that will use this instance of vertex tensorboard.\n",
    "\n",
    "    Obs: This code create always a tensorboard instance, with the same name (display_name) but different ID, so it is necessary RUN ONCE\n",
    "    \n",
    "    Args\n",
    "        experiment_name (string)\n",
    "        experiment_description (string)\n",
    "        project_gcp (string)\n",
    "        location_gcp (string)\n",
    "\n",
    "    Return\n",
    "        id_experiment_tensorboard (vertex ai tensorboard object)\n",
    "    \"\"\"\n",
    "    id_tensorboard_vertex = vertex_ai.Tensorboard.create(display_name = f'tensorboard-{experiment_name}',\n",
    "                                                          description = f'tensorboard-{experiment_description}',\n",
    "                                                          project = project_gcp,\n",
    "                                                          location = location_gcp\n",
    "                                                         )\n",
    "    return id_tensorboard_vertex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c923a4ab-f8f7-4a4d-84ff-a1a041cccc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tensorboard_instance_or_create(experiment_name, experiment_description, project_gcp, location_gcp):\n",
    "    \"\"\"\n",
    "    Search if exist a tensorboard instance and get it. If the instance doesn't exist, create it.\n",
    "    The instance of tensorboard has its name with the idea to have the same name of the experiment of vertex ai that will use this instance\n",
    "    of vertex.\n",
    "\n",
    "    Args\n",
    "        experiment_name (string)\n",
    "        experiment_description (string)\n",
    "        project_gcp (string)\n",
    "        location_gcp (string)\n",
    "\n",
    "    Return\n",
    "        id_experiment_tensorboard (vertex ai tensorboard object)\n",
    "    \"\"\"\n",
    "    \n",
    "    ''' search tensorboard instance. if the list is empty the tensorboard instance doesn't exist and it will created '''\n",
    "    # GET tensorboard instance created FILTERING by display name. return a list of the instance doesn't exist return a empty list\n",
    "    list_tensorboard_vertex = vertex_ai.Tensorboard.list(\n",
    "        filter = f'display_name=\"tensorboard-{experiment_name}\"',\n",
    "        project = project_gcp,\n",
    "        location = location_gcp\n",
    "    )\n",
    "\n",
    "    # if vertex tensorboard instance doesn't exist, create it\n",
    "    if len(list_tensorboard_vertex) == 0:\n",
    "        print('--- creating vertex tensorboard instance ---')\n",
    "        id_tensorboard_vertex = vertex_ai.Tensorboard.create(display_name = f'tensorboard-{experiment_name}',\n",
    "                                                                 description = f'tensorboard-{experiment_description}',\n",
    "                                                                 project = project_gcp,\n",
    "                                                                 location = location_gcp\n",
    "                                                                ) # return tensorboard instance created\n",
    "    else:\n",
    "        print('--- tensorboard instance already exists ---')\n",
    "        id_tensorboard_vertex = list_tensorboard_vertex[0] # tensorboard instance exists, return it\n",
    "    \n",
    "    return id_tensorboard_vertex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc9f193-4073-4586-88e1-c53f7691febb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_local_to_gcs(uri_gcs, uri_local):\n",
    "    \"\"\"\n",
    "    AUXILIAR. Save a locally file onto GCS.\n",
    "    Args:\n",
    "        uri_gcs (string): path in gcs where the local file will be saved\n",
    "        uri_local (strring). path in local where the local file was saved\n",
    "\n",
    "    Return\n",
    "        nothing\n",
    "    \"\"\"\n",
    "\n",
    "    blob = storage.blob.Blob.from_string(uri_gcs, client=storage.Client())\n",
    "    blob.upload_from_filename(uri_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe236d8d-9c69-4cf2-9d9b-20abd49889fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_artifacts_experiments_vertex(path_artifact_locally, type_artifact, bucket_gcs, experiment_name, run_name):\n",
    "    \"\"\"\n",
    "    Save an artifact in experiments in vertex. This functions works for an individual artifact. The run of the experiment needs to be created\n",
    "    The input is a file saved locally and the output is the file registered as a artifact of a run of a vertex experiment\n",
    "    \n",
    "    There following steps are necesarys to save the artifact\n",
    "    - save artifact locally\n",
    "    - save artifact in GCS\n",
    "    - link the artifact in GCS with vertex metadata\n",
    "    - link vertex metadata with an artifact saved in a run (experiment vertex)\n",
    "    - delete the file locally\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. save artifact locally (done -input function)\n",
    "\n",
    "\n",
    "    # 2. save artifact in GCS\n",
    "    path_artifact_gcs = f'gs://{bucket_gcs}/{experiment_name}/{run_name}/{path_artifact_locally}'\n",
    "    save_local_to_gcs(uri_gcs = path_artifact_gcs, \n",
    "                      uri_local = path_artifact_locally)\n",
    "\n",
    "    \n",
    "    # 3. link the artifact in GCS with vertex metadata\n",
    "    path_artifact_locally_corrected = path_artifact_locally.replace('_', '-').replace('.', '-') # in the name only accepted \"-\"\n",
    "    path_artifact_locally_corrected = path_artifact_locally_corrected.lower() # in the name only acceted lower case [a-z0-9][a-z0-9-]{0,127}\n",
    "    \n",
    "    artifact_metadata = vertex_ai.Artifact.create(\n",
    "        schema_title = \"system.Artifact\", \n",
    "        uri = path_artifact_gcs, # \n",
    "        display_name = f\"artifact-{path_artifact_locally}\", # nombre con el que se muestra en el menu \"metadata\"\n",
    "        description = f\"description-{path_artifact_locally}\",\n",
    "        resource_id = f\"{path_artifact_locally_corrected}-{experiment_name}-{run_name}\"  # nombre con el que se muestra en el menu \"artifact del run del experimento\" de vertex. No acepta espacios\n",
    "        )\n",
    "\n",
    "\n",
    "    # 4. link vertex metadata with an artifact saved in a run \n",
    "    executions = vertex_ai.start_execution(\n",
    "        schema_title=\"system.ContainerExecution\", \n",
    "        display_name='REGISTRO DE ARTIFACTS'\n",
    "    )\n",
    "    executions.assign_input_artifacts([artifact_metadata])\n",
    "\n",
    "    \n",
    "    # 5. delete the file local\n",
    "    #os.remove(path_artifact_locally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67abfe56-cbc1-4c66-a988-24795384d3c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c77d535-0802-4738-8cf3-190f5337ccb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tensorboard instance. ONLY ONCE. THE FIRST TIME. \n",
    "#------> There is other code to search if a tensorboard instance exist and the create it\n",
    "\"\"\"\n",
    "experiment_tensorboard = create_instance_tensorboard(experiment_name = 'prueba_codes_final_v3',\n",
    "                                                     experiment_description = 'prueba de códigos final, empaquetado en funciones',\n",
    "                                                     project_gcp = PROJECT_GCP,\n",
    "                                                     location_gcp = LOCATION_GCP\n",
    "                                                    )\n",
    "experiment_tensorboard\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7fcc05-5485-4052-8c20-5cdfd48518ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "270eeb31-936c-4df2-9629-734d5c225f8a",
   "metadata": {},
   "source": [
    "#### 2.0 Parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286023b3-bc6a-4410-936c-54fa68a77b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS GCP\n",
    "\n",
    "# get environment variables from .env - only necesary using a jupyter notebook\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "# read env variables\n",
    "PROJECT_GCP = os.environ.get(\"PROJECT_GCP\", \"\")\n",
    "LOCATION_GCP = os.environ.get(\"LOCATION_GCP\", \"\")\n",
    "BUCKET_NAME = os.environ.get(\"BUCKET_NAME\", \"\")\n",
    "\n",
    "\n",
    "\n",
    "# PARAMETERS TO CREATE AN EXPERIMENT IN VERTEX AI\n",
    "# obs: In names only are accepted '[a-z0-9][a-z0-9-]{0,127}'\n",
    "EXPERIMENT_NAME = 'predictions-housing-prices'\n",
    "EXPERIMENT_DESCRIPTION = 'Test saving results of diferents runs in vertex experiments'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8199b2-bc7e-4dbf-9530-d14a627b1813",
   "metadata": {},
   "source": [
    "#### 2.1 Set experiment vertex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234fda87-82e3-4818-9718-ffba788ecc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search tensorboard instance, if it doesn't exist -> created it\n",
    "id_tensorboard_vertex = get_tensorboard_instance_or_create(experiment_name = EXPERIMENT_NAME,\n",
    "                                                           experiment_description = EXPERIMENT_DESCRIPTION,\n",
    "                                                           project_gcp = PROJECT_GCP,\n",
    "                                                           location_gcp = LOCATION_GCP\n",
    "                                                          )\n",
    "\n",
    "# set experiment (or created if it doesn't exist - automatically)\n",
    "print('\\n--- setting experiment vertex ai ---')\n",
    "vertex_ai.init(\n",
    "    experiment = EXPERIMENT_NAME,\n",
    "    experiment_description = EXPERIMENT_DESCRIPTION,\n",
    "    experiment_tensorboard = id_tensorboard_vertex,\n",
    "    project = PROJECT_GCP,\n",
    "    location = LOCATION_GCP,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49699cd-dadc-4683-9884-44b0bcd1cacc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "162ae479-a724-4670-88b8-6d3f454b7ecb",
   "metadata": {},
   "source": [
    "#### 2.1 linear regression (lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb47827-c946-47a2-b755-028e71b3931e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# get predictions\n",
    "y_test_predicted = lr.predict(X_test)\n",
    "\n",
    "# evaluate\n",
    "r2_lr, rmse_lr, mae_lr = evaluate_model(y_test, y_test_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c47ad59-fad0-47a7-9ff4-876fc9001cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" registry run in experiment \"\"\"\n",
    "RUN_NAME = \"run-lr\"\n",
    "\n",
    "# create a run\n",
    "vertex_ai.start_run(RUN_NAME)\n",
    "\n",
    "# define metrics to save. In a dicctionary\n",
    "metrics_to_save = {\n",
    "    'r2': r2_lr,\n",
    "    'rmse': rmse_lr,\n",
    "    'mae': mae_lr\n",
    "}\n",
    "\n",
    "# save metrics\n",
    "vertex_ai.log_metrics(metrics_to_save)\n",
    "\n",
    "# save graphs\n",
    "save_artifacts_experiments_vertex(path_artifact_locally = name_correleation_matrix, \n",
    "                                  type_artifact = 'artifact', \n",
    "                                  bucket_gcs = BUCKET_NAME, \n",
    "                                  experiment_name = EXPERIMENT_NAME, \n",
    "                                  run_name = RUN_NAME\n",
    "                                 )\n",
    "\n",
    "save_artifacts_experiments_vertex(path_artifact_locally = name_histograms_target, \n",
    "                                  type_artifact = 'artifact', \n",
    "                                  bucket_gcs = BUCKET_NAME, \n",
    "                                  experiment_name = EXPERIMENT_NAME, \n",
    "                                  run_name = RUN_NAME\n",
    "                                 )\n",
    "\n",
    "\n",
    "# save model (but not registry)\n",
    "model_name = 'model.pkl'\n",
    "joblib.dump(lr, model_name) # save locally\n",
    "save_artifacts_experiments_vertex(path_artifact_locally = model_name,\n",
    "                                  type_artifact = 'artifact', \n",
    "                                  bucket_gcs = BUCKET_NAME, \n",
    "                                  experiment_name = EXPERIMENT_NAME, \n",
    "                                  run_name = RUN_NAME\n",
    "                                 )\n",
    "\n",
    "\n",
    "### terminar run\n",
    "vertex_ai.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84f6cfe-61ae-4876-a3b2-b49b69a80133",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4ea31b-c7d4-447b-829e-83da162ebfec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a0af339-c373-4054-bbdc-5f3281979707",
   "metadata": {},
   "source": [
    "# TODO: PASS ARGS OF TRAINING AS **ARGS AND THIS SAME VALUES SEE IF I CAN SAVE IN VERTEX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02549234-79b1-4d9b-a54b-378144d92926",
   "metadata": {},
   "source": [
    "#### 2.2 decision tree (tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e487260-4ed7-40d5-ab90-fb8c8def501a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### parameters\n",
    "max_depth_tree = 15\n",
    "min_samples_split_tree = 10 \n",
    "min_samples_leaf_tree = 10\n",
    "\n",
    "\n",
    "# train model\n",
    "tree = DecisionTreeRegressor(max_depth = max_depth_tree,\n",
    "                             min_samples_split = min_samples_split_tree,\n",
    "                             min_samples_leaf = min_samples_leaf_tree,\n",
    "                             random_state=42\n",
    "                            )\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# get predictions\n",
    "y_test_predicted = tree.predict(X_test)\n",
    "\n",
    "\n",
    "# evaluate\n",
    "r2_tree, rmse_tree, mae_tree = evaluate_model(y_test, y_test_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89807a62-9d6c-4d34-ab6a-6d1ff0f9dd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" registry run in experiment \"\"\"\n",
    "RUN_NAME = \"run-tree\"\n",
    "\n",
    "# create a run\n",
    "vertex_ai.start_run(RUN_NAME)\n",
    "\n",
    "# define params to save. In a dicctionary\n",
    "params_to_save = {\n",
    "    'max_depth': max_depth_tree,\n",
    "    'min_samples_split': min_samples_split_tree,\n",
    "    'min_samples_leaf': min_samples_leaf_tree\n",
    "}\n",
    "\n",
    "# save parameters\n",
    "vertex_ai.log_params(params_to_save)\n",
    "\n",
    "# define metrics to save. In a dicctionary\n",
    "metrics_to_save = {\n",
    "    'r2': r2_tree,\n",
    "    'rmse': rmse_tree,\n",
    "    'mae': mae_tree\n",
    "}\n",
    "\n",
    "# save metrics\n",
    "vertex_ai.log_metrics(metrics_to_save)\n",
    "\n",
    "\n",
    "# save graphs\n",
    "save_artifacts_experiments_vertex(path_artifact_locally = name_correleation_matrix, \n",
    "                                  type_artifact = 'artifact', \n",
    "                                  bucket_gcs = BUCKET_NAME, \n",
    "                                  experiment_name = EXPERIMENT_NAME, \n",
    "                                  run_name = RUN_NAME\n",
    "                                 )\n",
    "\n",
    "save_artifacts_experiments_vertex(path_artifact_locally = name_histograms_target, \n",
    "                                  type_artifact = 'artifact', \n",
    "                                  bucket_gcs = BUCKET_NAME, \n",
    "                                  experiment_name = EXPERIMENT_NAME, \n",
    "                                  run_name = RUN_NAME\n",
    "                                 )\n",
    "\n",
    "# save model (but not registry)\n",
    "model_name = 'model.pkl'\n",
    "joblib.dump(tree, model_name) # save locally\n",
    "save_artifacts_experiments_vertex(path_artifact_locally = model_name,\n",
    "                                  type_artifact = 'artifact', \n",
    "                                  bucket_gcs = BUCKET_NAME, \n",
    "                                  experiment_name = EXPERIMENT_NAME, \n",
    "                                  run_name = RUN_NAME\n",
    "                                 )\n",
    "\n",
    "\n",
    "### terminar run\n",
    "vertex_ai.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb3e800-2a43-4b57-883d-9436217e564b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14d7bf6-cd96-42b1-bfd0-5c4f51c2387d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77e6ac4-8113-472e-86d5-1fd1f58d61ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e6ae324-6c10-4554-82c5-f303ace4c97d",
   "metadata": {},
   "source": [
    "#### 2.3 random forest (small) (rf_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e91eff9-2baa-433d-9450-1045a7ba36be",
   "metadata": {},
   "outputs": [],
   "source": [
    "### parameters\n",
    "n_estimators_rf_small = 5\n",
    "max_depth_rf_small = 50\n",
    "min_samples_split_rf_small = 10 \n",
    "min_samples_leaf_rf_small = 10\n",
    "\n",
    "\n",
    "# train model\n",
    "rf_small = RandomForestRegressor(n_estimators = n_estimators_rf_small,\n",
    "                                   max_depth = max_depth_rf_small,\n",
    "                                   min_samples_split = min_samples_split_rf_small,\n",
    "                                   min_samples_leaf = min_samples_leaf_rf_small,\n",
    "                                   random_state=42\n",
    "                                  )\n",
    "rf_small.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# get predictions\n",
    "y_test_predicted = rf_small.predict(X_test)\n",
    "\n",
    "\n",
    "# evaluate\n",
    "r2_rf_small, rmse_rf_small, mae_rf_small = evaluate_model(y_test, y_test_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7164ab-3207-4871-b8dd-984dd45167c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" registry run in experiment \"\"\"\n",
    "RUN_NAME = \"run-rf-small\"\n",
    "\n",
    "# create a run\n",
    "vertex_ai.start_run(RUN_NAME)\n",
    "\n",
    "# define params to save. In a dicctionary\n",
    "params_to_save = {\n",
    "    'n_estimators': n_estimators_rf_small,\n",
    "    'max_depth': max_depth_rf_small,\n",
    "    'min_samples_split': min_samples_split_rf_small,\n",
    "    'min_samples_leaf': min_samples_leaf_rf_small\n",
    "}\n",
    "\n",
    "# save parameters\n",
    "vertex_ai.log_params(params_to_save)\n",
    "\n",
    "# define metrics to save. In a dicctionary\n",
    "metrics_to_save = {\n",
    "    'r2': r2_rf_small,\n",
    "    'rmse': rmse_rf_small,\n",
    "    'mae': mae_rf_small\n",
    "}\n",
    "\n",
    "# save metrics\n",
    "vertex_ai.log_metrics(metrics_to_save)\n",
    "\n",
    "\n",
    "# save graphs\n",
    "save_artifacts_experiments_vertex(path_artifact_locally = name_correleation_matrix, \n",
    "                                  type_artifact = 'artifact', \n",
    "                                  bucket_gcs = BUCKET_NAME, \n",
    "                                  experiment_name = EXPERIMENT_NAME, \n",
    "                                  run_name = RUN_NAME\n",
    "                                 )\n",
    "\n",
    "save_artifacts_experiments_vertex(path_artifact_locally = name_histograms_target, \n",
    "                                  type_artifact = 'artifact', \n",
    "                                  bucket_gcs = BUCKET_NAME, \n",
    "                                  experiment_name = EXPERIMENT_NAME, \n",
    "                                  run_name = RUN_NAME\n",
    "                                 )\n",
    "\n",
    "# save model (but not registry)\n",
    "model_name = 'model.pkl'\n",
    "joblib.dump(rf_small, model_name) # save locally\n",
    "save_artifacts_experiments_vertex(path_artifact_locally = model_name,\n",
    "                                  type_artifact = 'artifact', \n",
    "                                  bucket_gcs = BUCKET_NAME, \n",
    "                                  experiment_name = EXPERIMENT_NAME, \n",
    "                                  run_name = RUN_NAME\n",
    "                                 )\n",
    "\n",
    "\n",
    "### terminar run\n",
    "vertex_ai.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700de8db-55f2-40a3-9067-21799af7932f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31479de5-312e-43a1-903e-a8c1754aa7ce",
   "metadata": {},
   "source": [
    "#### 2.4 random forest (medium) (rf_medium)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e62c20-c3e0-453a-bdcd-8629521b2303",
   "metadata": {},
   "outputs": [],
   "source": [
    "### parameters\n",
    "n_estimators_rf_medium = 30\n",
    "max_depth_rf_medium = 50\n",
    "min_samples_split_rf_medium = 10 \n",
    "min_samples_leaf_rf_medium = 10\n",
    "\n",
    "# define params\n",
    "### TODO: SEE THAT PARAMS INPUT IN THE MODEL ARE USED TO REGISTRY IN VERTEX EXPERIMENTS\n",
    "params_to_save = {\n",
    "    'n_estimators': n_estimators_rf_medium,\n",
    "    'max_depth': max_depth_rf_medium,\n",
    "    'min_samples_split': min_samples_split_rf_medium,\n",
    "    'min_samples_leaf': min_samples_leaf_rf_medium\n",
    "}\n",
    "\n",
    "# train model\n",
    "rf_medium = RandomForestRegressor(**params_to_save,\n",
    "                                   random_state=42\n",
    "                                  )\n",
    "rf_medium.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# get predictions\n",
    "y_test_predicted = rf_medium.predict(X_test)\n",
    "\n",
    "\n",
    "# evaluate\n",
    "r2_rf_medium, rmse_rf_medium, mae_rf_medium = evaluate_model(y_test, y_test_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e554e6-a190-419d-b13b-dc4cf9a60e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" registry run in experiment \"\"\"\n",
    "RUN_NAME = \"run-rf-medium\"\n",
    "\n",
    "# create a run\n",
    "vertex_ai.start_run(RUN_NAME)\n",
    "\n",
    "\n",
    "# save parameters\n",
    "vertex_ai.log_params(params_to_save)\n",
    "\n",
    "# define metrics to save. In a dicctionary\n",
    "metrics_to_save = {\n",
    "    'r2': r2_rf_medium,\n",
    "    'rmse': rmse_rf_medium,\n",
    "    'mae': mae_rf_medium\n",
    "}\n",
    "\n",
    "# save metrics\n",
    "vertex_ai.log_metrics(metrics_to_save)\n",
    "\n",
    "\n",
    "# save graphs\n",
    "save_artifacts_experiments_vertex(path_artifact_locally = name_correleation_matrix, \n",
    "                                  type_artifact = 'artifact', \n",
    "                                  bucket_gcs = BUCKET_NAME, \n",
    "                                  experiment_name = EXPERIMENT_NAME, \n",
    "                                  run_name = RUN_NAME\n",
    "                                 )\n",
    "\n",
    "save_artifacts_experiments_vertex(path_artifact_locally = name_histograms_target, \n",
    "                                  type_artifact = 'artifact', \n",
    "                                  bucket_gcs = BUCKET_NAME, \n",
    "                                  experiment_name = EXPERIMENT_NAME, \n",
    "                                  run_name = RUN_NAME\n",
    "                                 )\n",
    "\n",
    "# save model (but not registry)\n",
    "model_name = 'model.pkl'\n",
    "joblib.dump(rf_medium, model_name) # save locally\n",
    "save_artifacts_experiments_vertex(path_artifact_locally = model_name,\n",
    "                                  type_artifact = 'artifact', \n",
    "                                  bucket_gcs = BUCKET_NAME, \n",
    "                                  experiment_name = EXPERIMENT_NAME, \n",
    "                                  run_name = RUN_NAME\n",
    "                                 )\n",
    "\n",
    "\n",
    "### terminar run\n",
    "vertex_ai.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9817a10-37fa-4874-a52b-52336aae2f62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de4af86-787a-46cd-ad28-498d1ffed70b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95b8276f-47e3-4e4f-b26d-2a6f23595480",
   "metadata": {},
   "source": [
    "#### 2.5 random forest (default) (rf_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce64dfb0-291f-4b84-8da9-641564f3382b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### parameters\n",
    "n_estimators_rf_default = 100\n",
    "max_depth_rf_default = 50\n",
    "min_samples_split_rf_default = 10 \n",
    "min_samples_leaf_rf_default = 10\n",
    "\n",
    "\n",
    "# define params\n",
    "### TODO: SEE THAT PARAMS INPUT IN THE MODEL ARE USED TO REGISTRY IN VERTEX EXPERIMENTS\n",
    "params_to_save = {\n",
    "    'n_estimators': n_estimators_rf_default,\n",
    "    'max_depth': max_depth_rf_default,\n",
    "    'min_samples_split': min_samples_split_rf_default,\n",
    "    'min_samples_leaf': min_samples_leaf_rf_default\n",
    "}\n",
    "\n",
    "# train model\n",
    "rf_default = RandomForestRegressor(**params_to_save,\n",
    "                                   random_state=42\n",
    "                                  )\n",
    "rf_default.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# get predictions\n",
    "y_test_predicted = rf_default.predict(X_test)\n",
    "\n",
    "\n",
    "# evaluate\n",
    "r2_rf_default, rmse_rf_default, mae_rf_default = evaluate_model(y_test, y_test_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b643908-d458-4d4a-9989-144d0baead33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" registry run in experiment \"\"\"\n",
    "RUN_NAME = \"run-rf-default\"\n",
    "\n",
    "# create a run\n",
    "vertex_ai.start_run(RUN_NAME)\n",
    "\n",
    "# save parameters\n",
    "vertex_ai.log_params(params_to_save)\n",
    "\n",
    "# define metrics to save. In a dicctionary\n",
    "metrics_to_save = {\n",
    "    'r2': r2_rf_default,\n",
    "    'rmse': rmse_rf_default,\n",
    "    'mae': mae_rf_default\n",
    "}\n",
    "\n",
    "# save metrics\n",
    "vertex_ai.log_metrics(metrics_to_save)\n",
    "\n",
    "\n",
    "# save graphs\n",
    "save_artifacts_experiments_vertex(path_artifact_locally = name_correleation_matrix, \n",
    "                                  type_artifact = 'artifact', \n",
    "                                  bucket_gcs = BUCKET_NAME, \n",
    "                                  experiment_name = EXPERIMENT_NAME, \n",
    "                                  run_name = RUN_NAME\n",
    "                                 )\n",
    "\n",
    "save_artifacts_experiments_vertex(path_artifact_locally = name_histograms_target, \n",
    "                                  type_artifact = 'artifact', \n",
    "                                  bucket_gcs = BUCKET_NAME, \n",
    "                                  experiment_name = EXPERIMENT_NAME, \n",
    "                                  run_name = RUN_NAME\n",
    "                                 )\n",
    "\n",
    "# save model (but not registry)\n",
    "model_name = 'model.pkl'\n",
    "joblib.dump(rf_default, model_name) # save locally\n",
    "save_artifacts_experiments_vertex(path_artifact_locally = model_name,\n",
    "                                  type_artifact = 'artifact', \n",
    "                                  bucket_gcs = BUCKET_NAME, \n",
    "                                  experiment_name = EXPERIMENT_NAME, \n",
    "                                  run_name = RUN_NAME\n",
    "                                 )\n",
    "\n",
    "\n",
    "### terminar run\n",
    "vertex_ai.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcc9027-97f2-4a7f-98b4-20632728c22f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc051c1-adfb-4e7f-bd19-4ec2580de955",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a503ab6-a065-44b5-86b7-e2b82feb6186",
   "metadata": {},
   "source": [
    "#### 2.6 NN MLP (mlp-sk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f33313d-3527-45e4-be79-bdb5d8d04605",
   "metadata": {},
   "outputs": [],
   "source": [
    "### parameters\n",
    "hidden_layer_sizes_nn_mlp = [200, 100, 50, 25]\n",
    "activation_nn_mlp = 'relu'\n",
    "learning_rate_init_nn_mlp = 0.001\n",
    "max_iter_nn_mlp = 200\n",
    "early_stopping_nn_mlp = True\n",
    "validation_fraction_nn_mlp = 0.1\n",
    "\n",
    "# train model\n",
    "nn_mlp = MLPRegressor(hidden_layer_sizes = hidden_layer_sizes_nn_mlp,\n",
    "                      activation = activation_nn_mlp,\n",
    "                      learning_rate_init = learning_rate_init_nn_mlp,\n",
    "                      max_iter = max_iter_nn_mlp,\n",
    "                      early_stopping = early_stopping_nn_mlp,\n",
    "                      validation_fraction = validation_fraction_nn_mlp,\n",
    "                      random_state = 42\n",
    "                     )\n",
    "nn_mlp.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# get predictions\n",
    "y_test_predicted = nn_mlp.predict(X_test)\n",
    "\n",
    "\n",
    "# evaluate\n",
    "r2_nn_mlp, rmse_nn_mlp, mae_nn_mlp = evaluate_model(y_test, y_test_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c7f4e5-cfbc-471a-8acd-baa9ebef1bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" registry run in experiment \"\"\"\n",
    "RUN_NAME = \"run-mlp-sk\"\n",
    "\n",
    "# create a run\n",
    "vertex_ai.start_run(RUN_NAME)\n",
    "\n",
    "# define params to save. In a dicctionary\n",
    "params_to_save = {\n",
    "    'hidden_layer_sizes_nn_mlp': '[200, 100, 50, 25]',  # only accepted float, integer or string\n",
    "    'activation_nn_mlp': activation_nn_mlp,\n",
    "    'learning_rate_init_nn_mlp': learning_rate_init_nn_mlp,\n",
    "    'max_iter_nn_mlp': max_iter_nn_mlp,\n",
    "    'early_stopping_nn_mlp': True,\n",
    "    'validation_fraction_nn_mlp': validation_fraction_nn_mlp\n",
    "}\n",
    "\n",
    "# save parameters\n",
    "vertex_ai.log_params(params_to_save)\n",
    "\n",
    "# define metrics to save. In a dicctionary\n",
    "metrics_to_save = {\n",
    "    'r2': r2_nn_mlp,\n",
    "    'rmse': rmse_nn_mlp,\n",
    "    'mae': mae_nn_mlp\n",
    "}\n",
    "\n",
    "# save metrics\n",
    "vertex_ai.log_metrics(metrics_to_save)\n",
    "\n",
    "\n",
    "\n",
    "# save graphs\n",
    "save_artifacts_experiments_vertex(path_artifact_locally = name_correleation_matrix, \n",
    "                                  type_artifact = 'artifact', \n",
    "                                  bucket_gcs = BUCKET_NAME, \n",
    "                                  experiment_name = EXPERIMENT_NAME, \n",
    "                                  run_name = RUN_NAME\n",
    "                                 )\n",
    "\n",
    "save_artifacts_experiments_vertex(path_artifact_locally = name_histograms_target, \n",
    "                                  type_artifact = 'artifact', \n",
    "                                  bucket_gcs = BUCKET_NAME, \n",
    "                                  experiment_name = EXPERIMENT_NAME, \n",
    "                                  run_name = RUN_NAME\n",
    "                                 )\n",
    "\n",
    "# save model (but not registry)\n",
    "model_name = 'model.pkl'\n",
    "joblib.dump(nn_mlp, model_name) # save locally\n",
    "save_artifacts_experiments_vertex(path_artifact_locally = model_name,\n",
    "                                  type_artifact = 'artifact', \n",
    "                                  bucket_gcs = BUCKET_NAME, \n",
    "                                  experiment_name = EXPERIMENT_NAME, \n",
    "                                  run_name = RUN_NAME\n",
    "                                 )\n",
    "\n",
    "\n",
    "\n",
    "### terminar run\n",
    "vertex_ai.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025b3363-53f6-4c28-9f4b-fa8ae4f06e42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef78b00-f893-4040-8bbf-fff1a9f25e25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e2291f-63e9-4717-8e46-20a3cf9a6752",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3cc508-ff77-429d-a492-fe469ddffe3a",
   "metadata": {},
   "source": [
    "#### 2.2 Extra - explore the efect of change \"max_depth\"\n",
    "- Explore the efect changing the maximum depth of the tree\n",
    "\n",
    "- Instead of doing a hp tunning, the idea is changing the values of \"max_depth\" and SEE IN VERTEX the efect of changing only one hiper-parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d64e38f-2774-4fe8-9455-ad8bef35eb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### SET EXPERIMENT\n",
    "\n",
    "EXPERIMENT_NAME_DEPTH = 'usecase-housing-price-depth'\n",
    "EXPERIMENT_DESCRIPTION_DEPTH = 'see the efect of changing the parameter max_depth in tree regressor'\n",
    "\n",
    "# search tensorboard instance, if it doesn't exist -> created it\n",
    "id_tensorboard_vertex = get_tensorboard_instance_or_create(experiment_name = EXPERIMENT_NAME_DEPTH,\n",
    "                                                           experiment_description = EXPERIMENT_DESCRIPTION_DEPTH,\n",
    "                                                           project_gcp = PROJECT_GCP,\n",
    "                                                           location_gcp = LOCATION_GCP\n",
    "                                                          )\n",
    "\n",
    "# set experiment (or created if it doesn't exist - automatically)\n",
    "print('\\n--- setting experiment vertex ai ---')\n",
    "vertex_ai.init(\n",
    "    experiment = EXPERIMENT_NAME_DEPTH,\n",
    "    experiment_description = EXPERIMENT_DESCRIPTION_DEPTH,\n",
    "    experiment_tensorboard = id_tensorboard_vertex,\n",
    "    project = PROJECT_GCP,\n",
    "    location = LOCATION_GCP,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efab49e2-8927-453e-87cf-285af97064aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### parameters\n",
    "max_depth_tree = [1,2,3,4,5,6,7,8,9,10]\n",
    "min_samples_split_tree = 10\n",
    "min_samples_leaf_tree = 20\n",
    "\n",
    "\n",
    "# train model\n",
    "for iter_max_depth in max_depth_tree:\n",
    "    \n",
    "    #### TRAIN AND EVALUATE\n",
    "    tree = DecisionTreeRegressor(max_depth = iter_max_depth,\n",
    "                                 min_samples_split = min_samples_split_tree,\n",
    "                                 min_samples_leaf = min_samples_leaf_tree,\n",
    "                                 random_state = 42\n",
    "                                )\n",
    "    tree.fit(X_train, y_train)\n",
    "    y_test_predicted = tree.predict(X_test)\n",
    "    r2_tree, rmse_tree, mae_tree = evaluate_model(y_test, y_test_predicted)\n",
    "\n",
    "\n",
    "    #### SAVE VERTEX\n",
    "    RUN_NAME = f\"run-tree-depth-{iter_max_depth}\"\n",
    "    \n",
    "    # create a run\n",
    "    vertex_ai.start_run(RUN_NAME)\n",
    "    \n",
    "    # define params to save. In a dicctionary\n",
    "    params_to_save = {\n",
    "        'max-depth-tree': iter_max_depth,\n",
    "        'split-tree': min_samples_split_tree,\n",
    "        'leaf-tree': min_samples_leaf_tree\n",
    "    }\n",
    "    \n",
    "    # save parameters\n",
    "    vertex_ai.log_params(params_to_save)\n",
    "    \n",
    "    # define metrics to save. In a dicctionary\n",
    "    metrics_to_save = {\n",
    "        'r2': r2_tree,\n",
    "        'rmse': rmse_tree,\n",
    "        'mae': mae_tree\n",
    "    }\n",
    "    \n",
    "    # save metrics\n",
    "    vertex_ai.log_metrics(metrics_to_save)\n",
    "    \n",
    "    ### terminar run\n",
    "    vertex_ai.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105bf732-bce3-4ae2-9c01-54b3a2221265",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296f9bf6-ebb1-4329-9568-f1c505fc40ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85472d39-43fc-48e9-9a19-dcdbaeb295bb",
   "metadata": {},
   "source": [
    "### 8. Delete files saved locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac85281-99bf-4552-afe7-5c92b455a9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### delete local files\n",
    "os.remove(model_name)\n",
    "os.remove(name_correleation_matrix)\n",
    "os.remove(name_histograms_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fe2580-b679-414f-b9ae-678a73e2a7d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
