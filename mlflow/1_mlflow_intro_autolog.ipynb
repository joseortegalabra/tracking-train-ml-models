{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93b3b6e2-122b-4c2a-9cd4-9281e2df5797",
   "metadata": {},
   "source": [
    "# Intro autolog mlflow\n",
    "\n",
    "Links examples:\n",
    "\n",
    "- sklearn: https://mlflow.org/docs/latest/python_api/mlflow.sklearn.html#mlflow.sklearn.autolog\n",
    "\n",
    "- tensorflow: https://github.com/mlflow/mlflow/blob/master/examples/keras/train.py\n",
    "\n",
    "- other examples: https://mlflow.org/docs/latest/tutorials-and-examples/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566a2b24-c28c-4a65-b47b-46b5cb762426",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "!pip show mlflow # version mflow used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2a3c2a-3a34-4b15-8ed4-9adbc8e13b3b",
   "metadata": {},
   "source": [
    "### 1. Autolog tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dfc3d6-e694-4c55-8276-d44cd9e23676",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Trains and evaluate a simple MLP\n",
    "on the Reuters newswire topic classification task.\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import reuters\n",
    "from tensorflow.keras.layers import Activation, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# The following import and function call are the only additions to code required\n",
    "# to automatically log metrics and parameters to MLflow.\n",
    "import mlflow\n",
    "\n",
    "mlflow.tensorflow.autolog()\n",
    "\n",
    "max_words = 1000\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "\n",
    "print(\"Loading data...\")\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=max_words, test_split=0.2)\n",
    "\n",
    "print(len(x_train), \"train sequences\")\n",
    "print(len(x_test), \"test sequences\")\n",
    "\n",
    "num_classes = np.max(y_train) + 1\n",
    "print(num_classes, \"classes\")\n",
    "\n",
    "print(\"Vectorizing sequence data...\")\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "x_train = tokenizer.sequences_to_matrix(x_train, mode=\"binary\")\n",
    "x_test = tokenizer.sequences_to_matrix(x_test, mode=\"binary\")\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"x_test shape:\", x_test.shape)\n",
    "\n",
    "print(\"Convert class vector to binary class matrix (for use with categorical_crossentropy)\")\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "print(\"Building model...\")\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(max_words,)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_split=0.1\n",
    ")\n",
    "score = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=1)\n",
    "print(\"Test score:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff0693d-e72b-49e4-bd42-8b3f8919509e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba7b92f-a429-4c9d-9cc4-22be23331ca3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22485b40-f14b-4e9f-a5f8-3ee4fe7aa868",
   "metadata": {},
   "source": [
    "### 2. Autolog sklearn\n",
    "Note: the version of sklearn used is not soported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07710694-d133-4309-8e01-6f1ae2fd2bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "#mlflow.sklearn.autolog() # oprueba autolog\n",
    "mlflow.sklearn.autolog()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    X = np.array([-2, -1, 0, 1, 2, 1, 10, 12, 23]).reshape(-1, 1)\n",
    "    y = np.array([0, 0, 1, 1, 1, 0, 0,0,0])\n",
    "    lr = LogisticRegression()\n",
    "\n",
    "    lr.fit(X, y)\n",
    "    score = lr.score(X, y)\n",
    "    print(f\"Score: {score}\")\n",
    "    #mlflow.log_metric(\"score\", score)\n",
    "    predictions = lr.predict(X)\n",
    "    signature = infer_signature(X, predictions)\n",
    "    mlflow.sklearn.log_model(lr, \"model\", signature=signature)\n",
    "    print(f\"Model saved in run {mlflow.active_run().info.run_uuid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f16f47-7591-4c95-8a42-6d2455b5f09a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
